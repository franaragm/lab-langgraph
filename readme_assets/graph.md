# ğŸ§  VisiÃ³n general del flujo

Tu grafo implementa este **patrÃ³n clÃ¡sico de Helpdesk 2.0**:

```
Usuario
  â†“
RAG (respuesta automÃ¡tica)
  â†“
ClasificaciÃ³n (Â¿confiamos en la respuesta?)
  â”œâ”€â”€ SÃ­ â†’ Respuesta final
  â””â”€â”€ No â†’ Escalado humano
               â†“
         Agente humano
```

No hay magia. Solo **control explÃ­cito del flujo y nodos especializados**.

---

# 1ï¸âƒ£ Nodos del grafo (quÃ© hace cada uno)

### ğŸ”¹ `rag` â†’ `run_rag`

* Ejecuta el pipeline RAG (`query_rag`)
* Busca documentos y genera una respuesta preliminar
* Calcula `confidence` heurÃ­stica
* **No decide nada**, solo produce informaciÃ³n

Ejemplo de estado que genera:

```python
{
  "rag_answer": "...",
  "confidence": 0.62,
  "sources": [...],
  "history": ["RAG ejecutado...", "Confianza heurÃ­stica...", "Fuentes consultadas..."]
}
```

---

### ğŸ”¹ `classify` â†’ `classify_with_context`

* Analiza la salida del RAG
* Decide **quÃ© camino tomar**: `automatic` o `escalated`
* No genera texto para el usuario
* Devuelve la categorÃ­a y justificaciÃ³n en `history`

Ejemplo:

```python
{
  "category": "automatic",
  "history": ["ClasificaciÃ³n realizada: automatic", "JustificaciÃ³n LLM: ..."]
}
```

âš ï¸ Este es el **nodo de decisiÃ³n principal**.

---

### ğŸ”¹ `escalation` â†’ `prepare_escalation`

* Marca el estado como pendiente de intervenciÃ³n humana (`requires_human = True`)
* AÃ±ade historial explicativo
* **No decide nada**, solo normaliza el estado antes del handoff

Ejemplo:

```python
{
  "requires_human": True,
  "human_answer": None,
  "history": ["Consulta escalada a agente humano."]
}
```

---

### ğŸ”¹ `process_human` â†’ `process_human_answer`

* Gestiona la respuesta del agente humano

* Puede:

  * Esperar input externo
  * Leer una cola
  * Recibir respuesta mock

* Genera `final_answer` con la respuesta humana

Ejemplo:

```python
{
  "final_answer": "Respuesta del agente humano",
  "history": ["Respuesta proporcionada por agente humano."]
}
```

---

### ğŸ”¹ `final_answer` â†’ `generate_final_answer`

* Toma la respuesta del RAG si no hay humano
* AÃ±ade fuentes y ajusta el formato
* Marca la respuesta final del ticket
* **No toma decisiones**, solo prepara la salida final

---

# 2ï¸âƒ£ Flujo de edges (cÃ³mo se mueve la informaciÃ³n)

```python
START â†’ rag â†’ classify
```

* Siempre empieza ejecutando RAG
* Luego `classify` evalÃºa si se entrega automÃ¡ticamente o se escala

### DecisiÃ³n principal

```python
graph.add_conditional_edges(
    "classify",
    route_after_classification,
    {
        "final_answer": "final_answer",
        "escalation": "escalation",
    }
)
```

FunciÃ³n tÃ­pica:

```python
def route_after_classification(state):
    return "final_answer" if state["category"] == "automatic" else "escalation"
```

---

### Camino A: Respuesta automÃ¡tica

```python
final_answer â†’ END
```

* Flujo corto
* Usuario recibe respuesta inmediata

---

### Camino B: Escalado humano

1. `classify â†’ escalation` â†’ marca `requires_human = True`
2. `escalation â†’ process_human` â†’ espera input humano
3. `process_human â†’ END` â†’ entrega respuesta final

---

# 3ï¸âƒ£ Checkpointer SQLite

```python
conn = sqlite3.connect("helpdesk.db", check_same_thread=False)
checkpointer = SqliteSaver(conn)
```

* Guarda el estado de cada nodo
* Permite reanudar flujos si hay crash o espera humana
* Mantiene `HelpdeskState`, historial y metadata

---

# 4ï¸âƒ£ CompilaciÃ³n del grafo

```python
graph.compile(
    checkpointer=checkpointer,
    interrupt_before=["process_human"],
)
```

* Convierte el grafo estÃ¡tico en **motor ejecutable**

* `interrupt_before=["process_human"]`:

  * Pausa el flujo antes del nodo humano
  * Guarda el estado en SQLite
  * Permite que la UI humana lo reanude

* Sin esto, `process_human` se ejecutarÃ­a automÃ¡ticamente y romperÃ­a la lÃ³gica human-in-the-loop

---

# 5ï¸âƒ£ Resumen mental

> ğŸ”¹ **RAG** produce informaciÃ³n
> ğŸ”¹ **Classify** decide el camino
> ğŸ”¹ **Escalation** marca estado
> ğŸ”¹ **Router** solo lee flags
> ğŸ”¹ **Final / Humano** cierran flujo

Este patrÃ³n **hace el flujo legible, testable y escalable**.

---

